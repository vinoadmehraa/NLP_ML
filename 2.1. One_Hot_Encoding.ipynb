{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571d73e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## One Hot Code Encoding Intution.\n",
    "\n",
    "# Text                   Output\n",
    "#D1 The food is good      1\n",
    "#D2 The food is bad       0\n",
    "#D3 Pizza is amazing      1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## In One Hot Encoding, first we need to find the all unique words.\n",
    "## Then, we need to convert each word in the form of vectors.\n",
    "\n",
    "## All Unique vocabulory\n",
    "## The food is good bad Pizza amazing -- This is the reference vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now convert each words based on unique vocabulary vectors.\n",
    "\n",
    "## Text\n",
    "## D1 [[1000000],\n",
    "#      [0100000],\n",
    "#      [0010000],\n",
    "#      [0001000]]\n",
    "## D2 [[1000000],[0100000],[0010000],[0000100]]\n",
    "## D3 [[0000010],[0100000],[0000001]]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Advantage and Disadvantage of One Hot Encoding.\n",
    "\n",
    "## Advantage\n",
    "## 1. Easy to implement with python (using sklean, OneHotEncoder library)\n",
    "\n",
    "## Disadvantage\n",
    "## 1. There are lot of zero'es for one word. And, it would lead to a sparse matrix.\n",
    "## This would lead to overfitting (very good accuracy with training but not good with new data)\n",
    "\n",
    "## 2. The length of the matrix for D3 is 3*7 however for D1 and D2 it is 4*7.\n",
    "## Due to variable size of matrix it would not be suitable for machine learning.\n",
    "\n",
    "## 3. No sementic meaning is captured. For instance, D1 is good and D2 is bad.\n",
    "## We can not measure how far is good and how far is bad.\n",
    "\n",
    "## 4. Out Of Vocabulory\n",
    "## If I trained the data with all unique word in the paragarph and if test data has some words\n",
    "## which are not in the training, then it would be out of vocabulory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b906ddb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2529b9d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54796a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1bf084",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
