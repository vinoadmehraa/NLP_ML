{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0979688b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## N Grams\n",
    "\n",
    "## S1 The food is good.\n",
    "## S2 The food is not good.\n",
    "\n",
    "## After using stopwords, we get vocabulory (food not good)\n",
    "\n",
    "## S1 -> [1 0 1]\n",
    "## S2 -> [1 1 1]\n",
    "\n",
    "## There is not much difference between S1 vector and S2 Vector.\n",
    "## however, S1 and S2 sentence are oppsite in meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bi-gram\n",
    "## Vocabulory is increased using words combination using bi-gram technique.\n",
    "## [food not good foodnot notgood foodgood]\n",
    "\n",
    "## Tri-gram\n",
    "## using three words combination.\n",
    "## [food not good foodnotgood]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/vinoadmehraa/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "porter_stemmer = PorterStemmer()\n",
    "messages = pd.read_csv('smsspamcollection/SMSSpamCollection',sep='\\t',names=[\"label\",\"message\"])\n",
    "\n",
    "corpus=[]\n",
    "for i in range(0,len(messages)):\n",
    "    review=re.sub('[^a-zA-Z]',' ',messages['message'][i])\n",
    "    review=review.lower()\n",
    "    review=review.split()\n",
    "    #print(review)\n",
    "    review=[porter_stemmer.stem(word) for word in review if word not in stopwords.words('english')]\n",
    "    review=' '.join(review)\n",
    "    corpus.append(review)\n",
    "\n",
    "cv=CountVectorizer(max_features=100,binary=True)\n",
    "X=cv.fit_transform(corpus).toarray()\n",
    "import numpy as np\n",
    "np.set_printoptions(edgeitems=30, linewidth=100000, \n",
    "    formatter=dict(float=lambda x: \"%.3g\" % x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815e4519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'go': 22,\n",
       " 'great': 25,\n",
       " 'got': 24,\n",
       " 'wat': 90,\n",
       " 'ok': 56,\n",
       " 'free': 18,\n",
       " 'win': 94,\n",
       " 'text': 77,\n",
       " 'txt': 85,\n",
       " 'say': 67,\n",
       " 'alreadi': 0,\n",
       " 'think': 80,\n",
       " 'hey': 28,\n",
       " 'week': 92,\n",
       " 'back': 3,\n",
       " 'like': 38,\n",
       " 'still': 73,\n",
       " 'send': 69,\n",
       " 'even': 15,\n",
       " 'friend': 19,\n",
       " 'prize': 62,\n",
       " 'claim': 7,\n",
       " 'call': 4,\n",
       " 'mobil': 47,\n",
       " 'co': 8,\n",
       " 'home': 30,\n",
       " 'want': 89,\n",
       " 'today': 82,\n",
       " 'cash': 6,\n",
       " 'day': 12,\n",
       " 'repli': 64,\n",
       " 'www': 96,\n",
       " 'right': 65,\n",
       " 'thank': 78,\n",
       " 'take': 75,\n",
       " 'time': 81,\n",
       " 'use': 87,\n",
       " 'messag': 44,\n",
       " 'oh': 55,\n",
       " 'ye': 97,\n",
       " 'make': 42,\n",
       " 'way': 91,\n",
       " 'feel': 16,\n",
       " 'dont': 14,\n",
       " 'miss': 46,\n",
       " 'ur': 86,\n",
       " 'tri': 84,\n",
       " 'da': 11,\n",
       " 'lor': 39,\n",
       " 'meet': 43,\n",
       " 'realli': 63,\n",
       " 'get': 20,\n",
       " 'know': 33,\n",
       " 'love': 40,\n",
       " 'let': 37,\n",
       " 'work': 95,\n",
       " 'wait': 88,\n",
       " 'yeah': 98,\n",
       " 'tell': 76,\n",
       " 'pleas': 61,\n",
       " 'msg': 49,\n",
       " 'see': 68,\n",
       " 'pl': 60,\n",
       " 'need': 51,\n",
       " 'tomorrow': 83,\n",
       " 'hope': 31,\n",
       " 'well': 93,\n",
       " 'lt': 41,\n",
       " 'gt': 26,\n",
       " 'ask': 1,\n",
       " 'morn': 48,\n",
       " 'happi': 27,\n",
       " 'sorri': 72,\n",
       " 'give': 21,\n",
       " 'new': 52,\n",
       " 'find': 17,\n",
       " 'year': 99,\n",
       " 'later': 35,\n",
       " 'pick': 59,\n",
       " 'good': 23,\n",
       " 'come': 9,\n",
       " 'said': 66,\n",
       " 'hi': 29,\n",
       " 'babe': 2,\n",
       " 'im': 32,\n",
       " 'much': 50,\n",
       " 'stop': 74,\n",
       " 'one': 57,\n",
       " 'night': 53,\n",
       " 'servic': 70,\n",
       " 'dear': 13,\n",
       " 'thing': 79,\n",
       " 'contact': 10,\n",
       " 'last': 34,\n",
       " 'min': 45,\n",
       " 'number': 54,\n",
       " 'leav': 36,\n",
       " 'sleep': 71,\n",
       " 'care': 5,\n",
       " 'phone': 58}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 100 words vocab with each word along with column index number not frequency.\n",
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngrams using unigram and bigrams (1,2)\n",
    "cv_ngrams=CountVectorizer(max_features=200,binary=True,ngram_range=(1,2))\n",
    "X=cv_ngrams.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1352e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'go': 50,\n",
       " 'great': 54,\n",
       " 'got': 53,\n",
       " 'wat': 183,\n",
       " 'ok': 116,\n",
       " 'free': 46,\n",
       " 'win': 189,\n",
       " 'st': 152,\n",
       " 'may': 93,\n",
       " 'text': 161,\n",
       " 'txt': 174,\n",
       " 'dun': 37,\n",
       " 'say': 137,\n",
       " 'alreadi': 0,\n",
       " 'think': 164,\n",
       " 'live': 82,\n",
       " 'around': 5,\n",
       " 'hey': 64,\n",
       " 'week': 186,\n",
       " 'word': 191,\n",
       " 'back': 9,\n",
       " 'like': 80,\n",
       " 'still': 154,\n",
       " 'send': 139,\n",
       " 'even': 39,\n",
       " 'per': 119,\n",
       " 'friend': 47,\n",
       " 'custom': 31,\n",
       " 'prize': 131,\n",
       " 'claim': 22,\n",
       " 'call': 14,\n",
       " 'hour': 69,\n",
       " 'mobil': 100,\n",
       " 'month': 102,\n",
       " 'co': 23,\n",
       " 'gonna': 51,\n",
       " 'home': 67,\n",
       " 'soon': 149,\n",
       " 'want': 182,\n",
       " 'talk': 159,\n",
       " 'stuff': 156,\n",
       " 'tonight': 172,\n",
       " 'today': 168,\n",
       " 'cash': 19,\n",
       " 'cost': 29,\n",
       " 'day': 33,\n",
       " 'repli': 134,\n",
       " 'urgent': 177,\n",
       " 'www': 194,\n",
       " 'right': 135,\n",
       " 'thank': 162,\n",
       " 'take': 158,\n",
       " 'help': 63,\n",
       " 'time': 167,\n",
       " 'use': 179,\n",
       " 'next': 109,\n",
       " 'messag': 96,\n",
       " 'com': 26,\n",
       " 'oh': 115,\n",
       " 'watch': 184,\n",
       " 'name': 106,\n",
       " 'ye': 196,\n",
       " 'make': 90,\n",
       " 'fine': 43,\n",
       " 'way': 185,\n",
       " 'feel': 41,\n",
       " 'dont': 36,\n",
       " 'miss': 99,\n",
       " 'ur': 176,\n",
       " 'tri': 173,\n",
       " 'first': 45,\n",
       " 'da': 32,\n",
       " 'finish': 44,\n",
       " 'lor': 85,\n",
       " 'meet': 95,\n",
       " 'realli': 133,\n",
       " 'get': 48,\n",
       " 'know': 73,\n",
       " 'lol': 83,\n",
       " 'alway': 2,\n",
       " 'love': 87,\n",
       " 'amp': 3,\n",
       " 'car': 17,\n",
       " 'let': 78,\n",
       " 'work': 192,\n",
       " 'wait': 180,\n",
       " 'sure': 157,\n",
       " 'us': 178,\n",
       " 'yeah': 197,\n",
       " 'tell': 160,\n",
       " 'anyth': 4,\n",
       " 'uk': 175,\n",
       " 'pleas': 127,\n",
       " 'look': 84,\n",
       " 'msg': 104,\n",
       " 'done': 35,\n",
       " 'see': 138,\n",
       " 'pl': 123,\n",
       " 'need': 107,\n",
       " 'sm': 145,\n",
       " 'nokia': 112,\n",
       " 'tomorrow': 170,\n",
       " 'pleas call': 128,\n",
       " 'hope': 68,\n",
       " 'man': 91,\n",
       " 'well': 187,\n",
       " 'lt': 88,\n",
       " 'gt': 55,\n",
       " 'lt gt': 89,\n",
       " 'could': 30,\n",
       " 'ask': 6,\n",
       " 'bit': 11,\n",
       " 'morn': 103,\n",
       " 'place': 124,\n",
       " 'thought': 166,\n",
       " 'best': 10,\n",
       " 'happi': 61,\n",
       " 'sorri': 150,\n",
       " 'give': 49,\n",
       " 'offer': 114,\n",
       " 'new': 108,\n",
       " 'play': 126,\n",
       " 'end': 38,\n",
       " 'find': 42,\n",
       " 'year': 198,\n",
       " 'special': 151,\n",
       " 'pm': 129,\n",
       " 'later': 76,\n",
       " 'call later': 15,\n",
       " 'reach': 132,\n",
       " 'pick': 122,\n",
       " 'good': 52,\n",
       " 'check': 21,\n",
       " 'come': 27,\n",
       " 'said': 136,\n",
       " 'nice': 110,\n",
       " 'award': 7,\n",
       " 'money': 101,\n",
       " 'hi': 65,\n",
       " 'babe': 8,\n",
       " 'im': 70,\n",
       " 'someth': 148,\n",
       " 'peopl': 118,\n",
       " 'much': 105,\n",
       " 'job': 71,\n",
       " 'stop': 155,\n",
       " 'one': 117,\n",
       " 'start': 153,\n",
       " 'night': 111,\n",
       " 'late': 75,\n",
       " 'mean': 94,\n",
       " 'smile': 146,\n",
       " 'someon': 147,\n",
       " 'servic': 141,\n",
       " 'guarante': 56,\n",
       " 'plan': 125,\n",
       " 'buy': 13,\n",
       " 'show': 143,\n",
       " 'collect': 25,\n",
       " 'box': 12,\n",
       " 'yet': 199,\n",
       " 'life': 79,\n",
       " 'lot': 86,\n",
       " 'dear': 34,\n",
       " 'wish': 190,\n",
       " 'would': 193,\n",
       " 'thing': 163,\n",
       " 'contact': 28,\n",
       " 'last': 74,\n",
       " 'ppm': 130,\n",
       " 'haha': 59,\n",
       " 'happen': 60,\n",
       " 'went': 188,\n",
       " 'holiday': 66,\n",
       " 'min': 97,\n",
       " 'number': 113,\n",
       " 'sent': 140,\n",
       " 'chat': 20,\n",
       " 'person': 120,\n",
       " 'heart': 62,\n",
       " 'gud': 57,\n",
       " 'ya': 195,\n",
       " 'thk': 165,\n",
       " 'leav': 77,\n",
       " 'keep': 72,\n",
       " 'also': 1,\n",
       " 'cant': 16,\n",
       " 'guy': 58,\n",
       " 'minut': 98,\n",
       " 'co uk': 24,\n",
       " 'everi': 40,\n",
       " 'sleep': 144,\n",
       " 'shop': 142,\n",
       " 'told': 169,\n",
       " 'care': 18,\n",
       " 'phone': 121,\n",
       " 'tone': 171,\n",
       " 'line': 81,\n",
       " 'mani': 92,\n",
       " 'wan': 181}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_ngrams.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7203d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngrams using bi-gram and tri-grams (2,3)\n",
    "cv_ngrams_new=CountVectorizer(max_features=10,binary=True,ngram_range=(2,3))\n",
    "X=cv_ngrams_new.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'let know': 3,\n",
       " 'pleas call': 5,\n",
       " 'lt gt': 4,\n",
       " 'sorri call': 7,\n",
       " 'call later': 0,\n",
       " 'sorri call later': 8,\n",
       " 'po box': 6,\n",
       " 'co uk': 1,\n",
       " 'good morn': 2,\n",
       " 'take care': 9}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_ngrams_new.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4efd422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfad3e34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
